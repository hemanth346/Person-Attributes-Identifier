{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Gyq8CE4ug5BK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Hemanth\n",
      " Volume Serial Number is 4466-01B4\n",
      "\n",
      " Directory of D:\\Projects\\PersonAttributesData\n",
      "\n",
      "18-12-2019  18:55    <DIR>          .\n",
      "18-12-2019  18:55    <DIR>          ..\n",
      "18-12-2019  18:55    <DIR>          .ipynb_checkpoints\n",
      "14-12-2019  12:23         1,576,476 hvc_annotations.csv\n",
      "14-12-2019  11:29       167,838,752 hvc_data.zip\n",
      "18-12-2019  18:53            17,160 PersonAttrubutes_new_updated.ipynb\n",
      "14-12-2019  12:23    <DIR>          resized\n",
      "               3 File(s)    169,432,388 bytes\n",
      "               4 Dir(s)  147,983,134,720 bytes free\n"
     ]
    }
   ],
   "source": [
    "# # mount gdrive and unzip data\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# !unzip -q \"/content/gdrive/My Drive/All_Datasets/hvc_data.zip\"\n",
    "# # look for `hvc_annotations.csv` file and `resized` dir\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cA7Wpdt5F1_5"
   },
   "source": [
    "4/uQGRZkPMeocjru0mO-U-ID42FaiDf7gr2UQC0WHDhIR9iPXZlgaDL1k\n",
    "\n",
    "4/uQE9dRivK1aHEZjKpfH_09ve3mJ8rJ1V44eHAP67j7YMoR3Ehob1yNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYbNQzK6kj94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path \n",
    "from tqdm import tqdm\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQkbSpLK4sTP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>imagequality</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>carryingbag</th>\n",
       "      <th>footwear</th>\n",
       "      <th>emotion</th>\n",
       "      <th>bodypose</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>Average</td>\n",
       "      <td>35-45</td>\n",
       "      <td>normal-healthy</td>\n",
       "      <td>Grocery/Home/Plastic Bag</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>Average</td>\n",
       "      <td>35-45</td>\n",
       "      <td>over-weight</td>\n",
       "      <td>None</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Angry/Serious</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>Good</td>\n",
       "      <td>45-55</td>\n",
       "      <td>normal-healthy</td>\n",
       "      <td>Grocery/Home/Plastic Bag</td>\n",
       "      <td>CantSee</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Good</td>\n",
       "      <td>45-55</td>\n",
       "      <td>normal-healthy</td>\n",
       "      <td>Daily/Office/Work Bag</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Good</td>\n",
       "      <td>35-45</td>\n",
       "      <td>slightly-overweight</td>\n",
       "      <td>None</td>\n",
       "      <td>CantSee</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender imagequality    age               weight               carryingbag  \\\n",
       "0    male      Average  35-45       normal-healthy  Grocery/Home/Plastic Bag   \n",
       "1  female      Average  35-45          over-weight                      None   \n",
       "2    male         Good  45-55       normal-healthy  Grocery/Home/Plastic Bag   \n",
       "3    male         Good  45-55       normal-healthy     Daily/Office/Work Bag   \n",
       "4  female         Good  35-45  slightly-overweight                      None   \n",
       "\n",
       "  footwear        emotion        bodypose     image_path  \n",
       "0   Normal        Neutral  Front-Frontish  resized/1.jpg  \n",
       "1   Normal  Angry/Serious  Front-Frontish  resized/2.jpg  \n",
       "2  CantSee        Neutral  Front-Frontish  resized/3.jpg  \n",
       "3   Normal        Neutral  Front-Frontish  resized/4.jpg  \n",
       "4  CantSee        Neutral  Front-Frontish  resized/5.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load annotations\n",
    "df = pd.read_csv(\"hvc_annotations.csv\")\n",
    "del df[\"filename\"] # remove unwanted column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'imagequality', 'age', 'weight', 'carryingbag', 'footwear',\n",
       "       'emotion', 'bodypose', 'image_path'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['gender', 'imagequality', 'age', 'weight', 'carryingbag', 'footwear',\n",
    "       'emotion', 'bodypose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_path</th>\n",
       "      <td>resized/1.jpg</td>\n",
       "      <td>resized/2.jpg</td>\n",
       "      <td>resized/3.jpg</td>\n",
       "      <td>resized/4.jpg</td>\n",
       "      <td>resized/5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_female</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_male</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Average</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Bad</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Good</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_15-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_25-35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_35-45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_45-55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_55+</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_normal-healthy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_over-weight</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_slightly-overweight</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_underweight</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_None</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_CantSee</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_Fancy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_Normal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Angry/Serious</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Happy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Neutral</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Sad</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Back</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Front-Frontish</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Side</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0              1  \\\n",
       "image_path                            resized/1.jpg  resized/2.jpg   \n",
       "gender_female                                     0              1   \n",
       "gender_male                                       1              0   \n",
       "imagequality_Average                              1              1   \n",
       "imagequality_Bad                                  0              0   \n",
       "imagequality_Good                                 0              0   \n",
       "age_15-25                                         0              0   \n",
       "age_25-35                                         0              0   \n",
       "age_35-45                                         1              1   \n",
       "age_45-55                                         0              0   \n",
       "age_55+                                           0              0   \n",
       "weight_normal-healthy                             1              0   \n",
       "weight_over-weight                                0              1   \n",
       "weight_slightly-overweight                        0              0   \n",
       "weight_underweight                                0              0   \n",
       "carryingbag_Daily/Office/Work Bag                 0              0   \n",
       "carryingbag_Grocery/Home/Plastic Bag              1              0   \n",
       "carryingbag_None                                  0              1   \n",
       "footwear_CantSee                                  0              0   \n",
       "footwear_Fancy                                    0              0   \n",
       "footwear_Normal                                   1              1   \n",
       "emotion_Angry/Serious                             0              1   \n",
       "emotion_Happy                                     0              0   \n",
       "emotion_Neutral                                   1              0   \n",
       "emotion_Sad                                       0              0   \n",
       "bodypose_Back                                     0              0   \n",
       "bodypose_Front-Frontish                           1              1   \n",
       "bodypose_Side                                     0              0   \n",
       "\n",
       "                                                  2              3  \\\n",
       "image_path                            resized/3.jpg  resized/4.jpg   \n",
       "gender_female                                     0              0   \n",
       "gender_male                                       1              1   \n",
       "imagequality_Average                              0              0   \n",
       "imagequality_Bad                                  0              0   \n",
       "imagequality_Good                                 1              1   \n",
       "age_15-25                                         0              0   \n",
       "age_25-35                                         0              0   \n",
       "age_35-45                                         0              0   \n",
       "age_45-55                                         1              1   \n",
       "age_55+                                           0              0   \n",
       "weight_normal-healthy                             1              1   \n",
       "weight_over-weight                                0              0   \n",
       "weight_slightly-overweight                        0              0   \n",
       "weight_underweight                                0              0   \n",
       "carryingbag_Daily/Office/Work Bag                 0              1   \n",
       "carryingbag_Grocery/Home/Plastic Bag              1              0   \n",
       "carryingbag_None                                  0              0   \n",
       "footwear_CantSee                                  1              0   \n",
       "footwear_Fancy                                    0              0   \n",
       "footwear_Normal                                   0              1   \n",
       "emotion_Angry/Serious                             0              0   \n",
       "emotion_Happy                                     0              0   \n",
       "emotion_Neutral                                   1              1   \n",
       "emotion_Sad                                       0              0   \n",
       "bodypose_Back                                     0              0   \n",
       "bodypose_Front-Frontish                           1              1   \n",
       "bodypose_Side                                     0              0   \n",
       "\n",
       "                                                  4  \n",
       "image_path                            resized/5.jpg  \n",
       "gender_female                                     1  \n",
       "gender_male                                       0  \n",
       "imagequality_Average                              0  \n",
       "imagequality_Bad                                  0  \n",
       "imagequality_Good                                 1  \n",
       "age_15-25                                         0  \n",
       "age_25-35                                         0  \n",
       "age_35-45                                         1  \n",
       "age_45-55                                         0  \n",
       "age_55+                                           0  \n",
       "weight_normal-healthy                             0  \n",
       "weight_over-weight                                0  \n",
       "weight_slightly-overweight                        1  \n",
       "weight_underweight                                0  \n",
       "carryingbag_Daily/Office/Work Bag                 0  \n",
       "carryingbag_Grocery/Home/Plastic Bag              0  \n",
       "carryingbag_None                                  1  \n",
       "footwear_CantSee                                  1  \n",
       "footwear_Fancy                                    0  \n",
       "footwear_Normal                                   0  \n",
       "emotion_Angry/Serious                             0  \n",
       "emotion_Happy                                     0  \n",
       "emotion_Neutral                                   1  \n",
       "emotion_Sad                                       0  \n",
       "bodypose_Back                                     0  \n",
       "bodypose_Front-Frontish                           1  \n",
       "bodypose_Side                                     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding of labels\n",
    "\n",
    "one_hot_df = pd.concat([\n",
    "    df[[\"image_path\"]],\n",
    "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
    "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
    "    pd.get_dummies(df.age, prefix=\"age\"),\n",
    "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
    "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
    "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
    "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
    "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
    "], axis = 1)\n",
    "\n",
    "one_hot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_df = pd.concat([pd.get_dummies(df[label], prefix=label) for label in labels], axis=1)\n",
    "# one_hot_df = pd.concat([df[\"image_path\"], one_hot_check], axis=1)\n",
    "# one_hot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'gender_female', 'gender_male', 'imagequality_Average',\n",
       "       'imagequality_Bad', 'imagequality_Good', 'age_15-25', 'age_25-35',\n",
       "       'age_35-45', 'age_45-55', 'age_55+', 'weight_normal-healthy',\n",
       "       'weight_over-weight', 'weight_slightly-overweight',\n",
       "       'weight_underweight', 'carryingbag_Daily/Office/Work Bag',\n",
       "       'carryingbag_Grocery/Home/Plastic Bag', 'carryingbag_None',\n",
       "       'footwear_CantSee', 'footwear_Fancy', 'footwear_Normal',\n",
       "       'emotion_Angry/Serious', 'emotion_Happy', 'emotion_Neutral',\n",
       "       'emotion_Sad', 'bodypose_Back', 'bodypose_Front-Frontish',\n",
       "       'bodypose_Side'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label columns per attribute\n",
    "\n",
    "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
    "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
    "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
    "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
    "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
    "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
    "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
    "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "0ll94zTv6w5i"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PersonDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Ground truth data generator \n",
    "\n",
    "    https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, batch_size=32, shuffle=True):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of batch in the Sequence.\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Gets batch at position index.\n",
    "\n",
    "        fetch batched images and targets        \n",
    "        \"\"\"\n",
    "        # slice function - https://www.w3schools.com/python/ref_func_slice.asp\n",
    "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
    "        items = self.df.iloc[batch_slice]\n",
    "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
    "        target = {\n",
    "            \"gender_output\": items[_gender_cols_].values,\n",
    "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
    "            \"age_output\": items[_age_cols_].values,\n",
    "            \"weight_output\": items[_weight_cols_].values,\n",
    "            \"bag_output\": items[_carryingbag_cols_].values,\n",
    "            \"pose_output\": items[_bodypose_cols_].values,\n",
    "            \"footwear_output\": items[_footwear_cols_].values,\n",
    "            \"emotion_output\": items[_emotion_cols_].values,\n",
    "        }\n",
    "        return image, target\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Shuffles/sample the df and thereby \n",
    "        updates indexes after each epoch\n",
    "        \n",
    "        Method called at the end of every epoch.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.shuffle == True:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "            # frac --> take sample of the given df, sample size is given as fraction number\n",
    "            # reset_index drop --> use the drop parameter to avoid the old index being added as a column\n",
    "            # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13573, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13573, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVE8-OaZ8J5q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11537, 28), (2036, 28))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5m15DLyF2ot"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>imagequality_Average</th>\n",
       "      <th>imagequality_Bad</th>\n",
       "      <th>imagequality_Good</th>\n",
       "      <th>age_15-25</th>\n",
       "      <th>age_25-35</th>\n",
       "      <th>age_35-45</th>\n",
       "      <th>age_45-55</th>\n",
       "      <th>...</th>\n",
       "      <th>footwear_CantSee</th>\n",
       "      <th>footwear_Fancy</th>\n",
       "      <th>footwear_Normal</th>\n",
       "      <th>emotion_Angry/Serious</th>\n",
       "      <th>emotion_Happy</th>\n",
       "      <th>emotion_Neutral</th>\n",
       "      <th>emotion_Sad</th>\n",
       "      <th>bodypose_Back</th>\n",
       "      <th>bodypose_Front-Frontish</th>\n",
       "      <th>bodypose_Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12632</th>\n",
       "      <td>resized/12634.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>resized/3088.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>resized/4974.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8587</th>\n",
       "      <td>resized/8588.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12876</th>\n",
       "      <td>resized/12878.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_path  gender_female  gender_male  imagequality_Average  \\\n",
       "12632  resized/12634.jpg              0            1                     0   \n",
       "3087    resized/3088.jpg              0            1                     1   \n",
       "4973    resized/4974.jpg              1            0                     1   \n",
       "8587    resized/8588.jpg              0            1                     0   \n",
       "12876  resized/12878.jpg              0            1                     1   \n",
       "\n",
       "       imagequality_Bad  imagequality_Good  age_15-25  age_25-35  age_35-45  \\\n",
       "12632                 0                  1          1          0          0   \n",
       "3087                  0                  0          0          1          0   \n",
       "4973                  0                  0          0          0          1   \n",
       "8587                  0                  1          0          1          0   \n",
       "12876                 0                  0          0          0          0   \n",
       "\n",
       "       age_45-55  ...  footwear_CantSee  footwear_Fancy  footwear_Normal  \\\n",
       "12632          0  ...                 0               0                1   \n",
       "3087           0  ...                 0               0                1   \n",
       "4973           0  ...                 0               1                0   \n",
       "8587           0  ...                 0               0                1   \n",
       "12876          1  ...                 0               1                0   \n",
       "\n",
       "       emotion_Angry/Serious  emotion_Happy  emotion_Neutral  emotion_Sad  \\\n",
       "12632                      0              0                0            1   \n",
       "3087                       0              0                1            0   \n",
       "4973                       0              0                0            1   \n",
       "8587                       0              0                1            0   \n",
       "12876                      0              0                1            0   \n",
       "\n",
       "       bodypose_Back  bodypose_Front-Frontish  bodypose_Side  \n",
       "12632              0                        1              0  \n",
       "3087               0                        1              0  \n",
       "4973               0                        1              0  \n",
       "8587               0                        1              0  \n",
       "12876              0                        1              0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTiOi5tVBnhS"
   },
   "outputs": [],
   "source": [
    "# create train and validation data generators\n",
    "train_gen = PersonDataGenerator(train_df, batch_size=32)\n",
    "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pMDGat-Ghow"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 2,\n",
       " 'image_quality': 3,\n",
       " 'age': 5,\n",
       " 'weight': 4,\n",
       " 'bag': 3,\n",
       " 'pose': 3,\n",
       " 'footwear': 3,\n",
       " 'emotion': 4}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of output units from data\n",
    "images, targets = next(iter(train_gen))\n",
    "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
    "num_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "19578880/58889256 [========>.....................] - ETA: 36:3 - ETA: 19:3 - ETA: 19:3 - ETA: 18:0 - ETA: 17:1 - ETA: 15:4 - ETA: 17:1 - ETA: 17:3 - ETA: 17:5 - ETA: 16:3 - ETA: 17:2 - ETA: 17:0 - ETA: 16:3 - ETA: 16:1 - ETA: 15:4 - ETA: 16:3 - ETA: 16:1 - ETA: 15:3 - ETA: 15:0 - ETA: 15:2 - ETA: 16:0 - ETA: 16:0 - ETA: 16:2 - ETA: 16:5 - ETA: 16:3 - ETA: 16:2 - ETA: 16:0 - ETA: 16:0 - ETA: 16:0 - ETA: 15:5 - ETA: 15:4 - ETA: 15:3 - ETA: 15:2 - ETA: 15:0 - ETA: 15:0 - ETA: 15:0 - ETA: 14:5 - ETA: 14:4 - ETA: 14:4 - ETA: 14:3 - ETA: 14:3 - ETA: 14:1 - ETA: 14:1 - ETA: 14:0 - ETA: 13:5 - ETA: 13:4 - ETA: 13:3 - ETA: 13:2 - ETA: 13:1 - ETA: 13:0 - ETA: 12:5 - ETA: 12:4 - ETA: 12:4 - ETA: 12:3 - ETA: 12:3 - ETA: 12:2 - ETA: 12:1 - ETA: 12:0 - ETA: 12:0 - ETA: 11:5 - ETA: 11:5 - ETA: 11:5 - ETA: 11:5 - ETA: 11:4 - ETA: 11:4 - ETA: 11:3 - ETA: 11:3 - ETA: 11:3 - ETA: 11:2 - ETA: 11:1 - ETA: 11:1 - ETA: 11:1 - ETA: 11:1 - ETA: 11:0 - ETA: 10:5 - ETA: 10:5 - ETA: 10:5 - ETA: 10:4 - ETA: 10:4 - ETA: 10:3 - ETA: 10:3 - ETA: 10:2 - ETA: 10:1 - ETA: 10:0 - ETA: 10:0 - ETA: 10:0 - ETA: 9:4 - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 8: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3:1758892288/58889256 [==============================] - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 45 - ETA: 45 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 162s 3us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x242273dbcf8>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = VGG16(\n",
    "    weights=\"imagenet\", \n",
    "    include_top=False, \n",
    "    input_tensor=Input(shape=(224, 224, 3))\n",
    ")\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x242273dbcf8>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neck = backbone.output\n",
    "neck = Flatten(name=\"flatten\")(neck)\n",
    "neck = Dense(512, activation=\"relu\")(neck)\n",
    "type(neck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03W8Pagg_Ppp"
   },
   "outputs": [],
   "source": [
    "backbone = VGG16(\n",
    "    weights=\"imagenet\", \n",
    "    include_top=False, \n",
    "    input_tensor=Input(shape=(224, 224, 3))\n",
    ")\n",
    "\n",
    "neck = backbone.output\n",
    "neck = Flatten(name=\"flatten\")(neck)\n",
    "neck = Dense(512, activation=\"relu\")(neck)\n",
    "\n",
    "\n",
    "def build_tower(in_layer):\n",
    "    # redundant\n",
    "#     neck = Dropout(0.2)(in_layer)\n",
    "#     neck = Dense(128, activation=\"relu\")(neck)\n",
    "    neck = Dropout(0.3)(in_layer)\n",
    "    neck = Dense(128, activation=\"relu\")(neck)\n",
    "    return neck\n",
    "\n",
    "\n",
    "def build_head(name, incoming):\n",
    "    return Dense(\n",
    "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
    "    )(incoming)\n",
    "\n",
    "# heads\n",
    "gender = build_head(\"gender\", build_tower(neck))\n",
    "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
    "age = build_head(\"age\", build_tower(neck))\n",
    "weight = build_head(\"weight\", build_tower(neck))\n",
    "bag = build_head(\"bag\", build_tower(neck))\n",
    "footwear = build_head(\"footwear\", build_tower(neck))\n",
    "emotion = build_head(\"emotion\", build_tower(neck))\n",
    "pose = build_head(\"pose\", build_tower(neck))\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=backbone.input, \n",
    "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxWVxcbi_y6V"
   },
   "outputs": [],
   "source": [
    "# freeze backbone\n",
    "for layer in backbone.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 25088)        0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          12845568    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65664       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          65664       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          65664       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          65664       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          65664       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          65664       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          65664       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          65664       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gender_output (Dense)           (None, 2)            258         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_quality_output (Dense)    (None, 3)            387         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "age_output (Dense)              (None, 5)            645         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "weight_output (Dense)           (None, 4)            516         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bag_output (Dense)              (None, 3)            387         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "footwear_output (Dense)         (None, 3)            387         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pose_output (Dense)             (None, 3)            387         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "emotion_output (Dense)          (None, 4)            516         dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 28,089,051\n",
      "Trainable params: 13,374,363\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, to_file='given_vgg_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfPG9C2eA1zn"
   },
   "outputs": [],
   "source": [
    "# losses = {\n",
    "# \t\"gender_output\": \"binary_crossentropy\",\n",
    "# \t\"image_quality_output\": \"categorical_crossentropy\",\n",
    "# \t\"age_output\": \"categorical_crossentropy\",\n",
    "# \t\"weight_output\": \"categorical_crossentropy\",\n",
    "\n",
    "# }\n",
    "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
    "opt = SGD(lr=0.001, momentum=0.9)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    # loss_weights=loss_weights, \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zw2ZRIQ7BW-Q"
   },
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpxv41EyNmN4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 570, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 553, in <lambda>\n",
      "    initargs=(seqs,))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 570, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 553, in <lambda>\n",
      "    initargs=(seqs,))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=1,\n",
    "    verbose=1\n",
    ")\n",
    "#     use_multiprocessing=True,\n",
    "#     workers=6, \n",
    "#     epochs=10,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zI1hJb4qM6OH"
   },
   "outputs": [],
   "source": [
    "dir(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "7_Nra8p4GMdz",
    "outputId": "faffa807-7887-4517-ca7e-cdf4ea689817"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_gender_output_loss', 'val_image_quality_output_loss', 'val_age_output_loss', 'val_weight_output_loss', 'val_bag_output_loss', 'val_footwear_output_loss', 'val_pose_output_loss', 'val_emotion_output_loss', 'val_gender_output_acc', 'val_image_quality_output_acc', 'val_age_output_acc', 'val_weight_output_acc', 'val_bag_output_acc', 'val_footwear_output_acc', 'val_pose_output_acc', 'val_emotion_output_acc', 'loss', 'gender_output_loss', 'image_quality_output_loss', 'age_output_loss', 'weight_output_loss', 'bag_output_loss', 'footwear_output_loss', 'pose_output_loss', 'emotion_output_loss', 'gender_output_acc', 'image_quality_output_acc', 'age_output_acc', 'weight_output_acc', 'bag_output_acc', 'footwear_output_acc', 'pose_output_acc', 'emotion_output_acc'])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGJ0HgBDMQOg"
   },
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOoE1nQGMxaR"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, predict_y):\n",
    "    C = confusion_matrix(y_test, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "   \n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "   \n",
    "    labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "    cmap=sns.light_palette(\"green\")\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*50, \"Confusion matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*50, \"Precision matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
    "    \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*50, \"Recall matrix\"    , \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of rows in precision matrix\",A.sum(axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoaX_SjOLXPQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PersonAttrubutes_new_updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
